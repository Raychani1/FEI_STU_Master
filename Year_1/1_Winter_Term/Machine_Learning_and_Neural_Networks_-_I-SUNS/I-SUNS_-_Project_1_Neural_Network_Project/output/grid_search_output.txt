Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[312 152]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[303 161]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[303 161]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[301 163]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[319 145]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[301 163]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.67       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[315 149]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[299 165]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[304 160]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[300 164]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[294 170]
 [123 651]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.63      0.67       464
           1       0.79      0.84      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[299 165]
 [124 650]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.64      0.67       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[292 172]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[304 160]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[302 162]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[302 162]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.67       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[317 147]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[302 162]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.67       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[299 165]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[306 158]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[295 169]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[299 165]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[295 169]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[298 166]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.84      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[306 158]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[291 173]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.63      0.65       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.75      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[307 157]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[296 168]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.64      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[298 166]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[307 157]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[294 170]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.63      0.65       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[284 180]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.61      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[292 172]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[309 155]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[288 176]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[291 173]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.63      0.65       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[284 180]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.61      0.65       464
           1       0.78      0.84      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.72      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[316 148]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[310 154]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.67       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[306 158]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.80      0.80      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[290 174]
 [124 650]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.62      0.66       464
           1       0.79      0.84      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[301 163]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[314 150]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[314 150]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[309 155]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[306 158]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[321 143]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.81      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[317 147]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[304 160]
 [164 610]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[302 162]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.65      0.66       464
           1       0.79      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[311 153]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[316 148]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[315 149]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[304 160]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[296 168]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[291 173]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.63      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[308 156]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[319 145]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.69       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[285 179]
 [118 656]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.61      0.66       464
           1       0.79      0.85      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.73      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[290 174]
 [124 650]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.62      0.66       464
           1       0.79      0.84      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[306 158]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[318 146]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[311 153]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[285 179]
 [122 652]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.61      0.65       464
           1       0.78      0.84      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[276 188]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.59      0.64       464
           1       0.78      0.84      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.75      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[332 132]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.72      0.70       464
           1       0.82      0.80      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.76      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[305 159]
 [168 606]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.66      0.65       464
           1       0.79      0.78      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[270 194]
 [123 651]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.58      0.63       464
           1       0.77      0.84      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[280 184]
 [113 661]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.60      0.65       464
           1       0.78      0.85      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.73      0.73      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[295 169]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[293 171]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[295 169]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[299 165]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[311 153]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[318 146]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[319 145]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[303 161]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[299 165]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[318 146]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[322 142]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.82      0.81      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[317 147]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[291 173]
 [119 655]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.63      0.67       464
           1       0.79      0.85      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[316 148]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[305 159]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[295 169]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[318 146]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.81      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[319 145]
 [174 600]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.69      0.67       464
           1       0.81      0.78      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[311 153]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[311 153]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[312 152]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[318 146]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[303 161]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[315 149]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.68      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[308 156]
 [166 608]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[302 162]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[312 152]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[300 164]
 [159 615]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.65      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[299 165]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[301 163]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.66       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[320 144]
 [180 594]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.69      0.66       464
           1       0.80      0.77      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.73      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[323 141]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.70      0.69       464
           1       0.81      0.80      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[342 122]
 [176 598]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.74      0.70       464
           1       0.83      0.77      0.80       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[314 150]
 [175 599]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.68      0.66       464
           1       0.80      0.77      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.73      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[294 170]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[273 191]
 [120 654]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.59      0.64       464
           1       0.77      0.84      0.81       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.75      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[295 169]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[300 164]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[299 165]
 [154 620]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[311 153]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[283 181]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.61      0.65       464
           1       0.78      0.83      0.81       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[294 170]
 [124 650]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.63      0.67       464
           1       0.79      0.84      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[302 162]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[313 151]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[310 154]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.67       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[305 159]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[318 146]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[316 148]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[304 160]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[317 147]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[314 150]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[307 157]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[312 152]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[318 146]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.69      0.67       464
           1       0.81      0.79      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.74      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[305 159]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[317 147]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[305 159]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[355 109]
 [204 570]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.77      0.69       464
           1       0.84      0.74      0.78       774

    accuracy                           0.75      1238
   macro avg       0.74      0.75      0.74      1238
weighted avg       0.76      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[289 175]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.62      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[308 156]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[311 153]
 [173 601]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.67      0.66       464
           1       0.80      0.78      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[269 195]
 [106 668]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.58      0.64       464
           1       0.77      0.86      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.72      0.73      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[283 181]
 [118 656]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.61      0.65       464
           1       0.78      0.85      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[300 164]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[305 159]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[311 153]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[325 139]
 [186 588]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.70      0.67       464
           1       0.81      0.76      0.78       774

    accuracy                           0.74      1238
   macro avg       0.72      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[288 176]
 [119 655]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.62      0.66       464
           1       0.79      0.85      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.73      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[298 166]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[273 191]
 [122 652]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.59      0.64       464
           1       0.77      0.84      0.81       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.75      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[286 178]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.62      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.75      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[259 205]
 [109 665]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.56      0.62       464
           1       0.76      0.86      0.81       774

    accuracy                           0.75      1238
   macro avg       0.73      0.71      0.72      1238
weighted avg       0.74      0.75      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[301 163]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[301 163]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.66       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[301 163]
 [154 620]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.66       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[313 151]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[313 151]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[304 160]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[313 151]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[310 154]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[306 158]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[311 153]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[315 149]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[307 157]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[302 162]
 [121 653]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.65      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[314 150]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[315 149]
 [125 649]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.68      0.70       464
           1       0.81      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[310 154]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[309 155]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[305 159]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[314 150]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[315 149]
 [125 649]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.68      0.70       464
           1       0.81      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[308 156]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[313 151]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[314 150]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[293 171]
 [116 658]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.63      0.67       464
           1       0.79      0.85      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[298 166]
 [123 651]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.64      0.67       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[318 146]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[317 147]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.70       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[310 154]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[313 151]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[317 147]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[310 154]
 [119 655]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.67      0.69       464
           1       0.81      0.85      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[356 108]
 [176 598]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.77      0.71       464
           1       0.85      0.77      0.81       774

    accuracy                           0.77      1238
   macro avg       0.76      0.77      0.76      1238
weighted avg       0.78      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[278 186]
 [103 671]]

Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.60      0.66       464
           1       0.78      0.87      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.73      0.74      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[305 159]
 [121 653]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.66      0.69       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[306 158]
 [125 649]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.66      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[317 147]
 [121 653]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.68      0.70       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[318 146]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[317 147]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.70       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[320 144]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[311 153]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[307 157]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[314 150]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[306 158]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[320 144]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[298 166]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.64      0.66       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[300 164]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.65      0.66       464
           1       0.79      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[301 163]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.75      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[309 155]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.67       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[304 160]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[308 156]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[322 142]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[317 147]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.69       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[317 147]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[305 159]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[307 157]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[323 141]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.70      0.70       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[313 151]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[331 133]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.71      0.70       464
           1       0.82      0.80      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.76      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[285 179]
 [116 658]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.61      0.66       464
           1       0.79      0.85      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.73      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[319 145]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[325 139]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.70      0.71       464
           1       0.82      0.84      0.83       774

    accuracy                           0.79      1238
   macro avg       0.77      0.77      0.77      1238
weighted avg       0.78      0.79      0.79      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[311 153]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[326 138]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.70      0.70       464
           1       0.82      0.81      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.76      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[322 142]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[313 151]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[319 145]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[304 160]
 [120 654]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.66      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[309 155]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[295 169]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[321 143]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[334 130]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.72      0.71       464
           1       0.83      0.81      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.77      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[326 138]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.70      0.70       464
           1       0.82      0.82      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[313 151]
 [125 649]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[304 160]
 [118 656]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.66      0.69       464
           1       0.80      0.85      0.83       774

    accuracy                           0.78      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[329 135]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.71      0.71       464
           1       0.82      0.82      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[313 151]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[320 144]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[293 171]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.63      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[309 155]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.67       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[316 148]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[313 151]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.67      0.67       464
           1       0.80      0.80      0.80       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[309 155]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[307 157]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[310 154]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[326 138]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.70      0.71       464
           1       0.82      0.83      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.77      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[296 168]
 [123 651]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.64      0.67       464
           1       0.79      0.84      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[331 133]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.71      0.70       464
           1       0.82      0.80      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[307 157]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[298 166]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[329 135]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.71      0.70       464
           1       0.82      0.81      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[315 149]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[319 145]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[324 140]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.70      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[310 154]
 [125 649]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[311 153]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[325 139]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.70      0.69       464
           1       0.82      0.80      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[339 125]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.73      0.71       464
           1       0.83      0.80      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.77      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[325 139]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.70      0.70       464
           1       0.82      0.82      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[283 181]
 [106 668]]

Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.61      0.66       464
           1       0.79      0.86      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.74      0.74      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[319 145]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.82      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[313 151]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[312 152]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[312 152]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[336 128]
 [165 609]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.72      0.70       464
           1       0.83      0.79      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.76      0.75      1238
weighted avg       0.77      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[329 135]
 [167 607]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.71      0.69       464
           1       0.82      0.78      0.80       774

    accuracy                           0.76      1238
   macro avg       0.74      0.75      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[323 141]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.70      0.70       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[318 146]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[324 140]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.70      0.70       464
           1       0.82      0.81      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[310 154]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[269 195]
 [ 94 680]]

Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.58      0.65       464
           1       0.78      0.88      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.73      0.74      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[318 146]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[311 153]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.67       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[315 149]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.68      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[319 145]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[288 176]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.62      0.65       464
           1       0.79      0.83      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[301 163]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.66       464
           1       0.80      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[319 145]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[299 165]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[313 151]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.67      0.67       464
           1       0.80      0.80      0.80       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[316 148]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.68      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[299 165]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[344 120]
 [177 597]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.74      0.70       464
           1       0.83      0.77      0.80       774

    accuracy                           0.76      1238
   macro avg       0.75      0.76      0.75      1238
weighted avg       0.77      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[296 168]
 [118 656]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.64      0.67       464
           1       0.80      0.85      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.74      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[310 154]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[350 114]
 [179 595]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.75      0.70       464
           1       0.84      0.77      0.80       774

    accuracy                           0.76      1238
   macro avg       0.75      0.76      0.75      1238
weighted avg       0.77      0.76      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[302 162]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[308 156]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[303 161]
 [124 650]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.65      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[317 147]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.69       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[328 136]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.71      0.70       464
           1       0.82      0.81      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.76      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[309 155]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[313 151]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[337 127]
 [171 603]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.73      0.69       464
           1       0.83      0.78      0.80       774

    accuracy                           0.76      1238
   macro avg       0.74      0.75      0.75      1238
weighted avg       0.77      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[350 114]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.75      0.72       464
           1       0.84      0.80      0.82       774

    accuracy                           0.78      1238
   macro avg       0.77      0.78      0.77      1238
weighted avg       0.79      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[343 121]
 [179 595]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.74      0.70       464
           1       0.83      0.77      0.80       774

    accuracy                           0.76      1238
   macro avg       0.74      0.75      0.75      1238
weighted avg       0.77      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[332 132]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.72      0.70       464
           1       0.83      0.81      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[327 137]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.70      0.70       464
           1       0.82      0.82      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[318 146]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[333 131]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.72      0.70       464
           1       0.82      0.79      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.76      0.75      1238
weighted avg       0.77      0.76      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[309 155]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[337 127]
 [178 596]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.73      0.69       464
           1       0.82      0.77      0.80       774

    accuracy                           0.75      1238
   macro avg       0.74      0.75      0.74      1238
weighted avg       0.76      0.75      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[293 171]
 [118 656]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.63      0.67       464
           1       0.79      0.85      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[356 108]
 [200 574]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.77      0.70       464
           1       0.84      0.74      0.79       774

    accuracy                           0.75      1238
   macro avg       0.74      0.75      0.74      1238
weighted avg       0.77      0.75      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[292 172]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.63      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[328 136]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.71      0.69       464
           1       0.82      0.80      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.76      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[280 184]
 [107 667]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.60      0.66       464
           1       0.78      0.86      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.73      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[298 166]
 [123 651]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.64      0.67       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[293 171]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[297 167]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[292 172]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.63      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[297 167]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[294 170]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[293 171]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[300 164]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[318 146]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[302 162]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[296 168]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[292 172]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.63      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[293 171]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[294 170]
 [154 620]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[288 176]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[292 172]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[306 158]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[305 159]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[298 166]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[291 173]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[289 175]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[292 172]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.63      0.65       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[286 178]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[287 177]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[291 173]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[297 167]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.64      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[311 153]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[308 156]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[289 175]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[293 171]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[290 174]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.65       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[285 179]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.61      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[286 178]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[290 174]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.65       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[285 179]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.61      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[306 158]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[286 178]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[305 159]
 [165 609]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[303 161]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[308 156]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[304 160]
 [161 613]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[304 160]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[308 156]
 [163 611]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[304 160]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[312 152]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[316 148]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[302 162]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.66       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[298 166]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[299 165]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[299 165]
 [159 615]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[293 171]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[296 168]
 [154 620]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[306 158]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[310 154]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[307 157]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[292 172]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[293 171]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[293 171]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[297 167]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[297 167]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[293 171]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[307 157]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[290 174]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[307 157]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[293 171]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[289 175]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[294 170]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[298 166]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[290 174]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[291 173]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[292 172]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[290 174]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[291 173]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[305 159]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[305 159]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.81      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[300 164]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[317 147]
 [168 606]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.68      0.67       464
           1       0.80      0.78      0.79       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[311 153]
 [164 610]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.67      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[302 162]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[319 145]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.68       464
           1       0.81      0.80      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[304 160]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[321 143]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[298 166]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.64      0.66       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[299 165]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[298 166]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.67       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[299 165]
 [159 615]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[306 158]
 [161 613]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[305 159]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[293 171]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.63      0.65       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[318 146]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[302 162]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[301 163]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[307 157]
 [166 608]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.66       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[297 167]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[297 167]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[299 165]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[301 163]
 [159 615]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.65      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[303 161]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[301 163]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.65      0.66       464
           1       0.79      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[294 170]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[298 166]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[294 170]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[299 165]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[299 165]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[289 175]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.65       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[293 171]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[289 175]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[292 172]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[294 170]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[310 154]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.67      0.67       464
           1       0.80      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[303 161]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[299 165]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.64      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[319 145]
 [175 599]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.69      0.67       464
           1       0.81      0.77      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[314 150]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[310 154]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[305 159]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[315 149]
 [166 608]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.68      0.67       464
           1       0.80      0.79      0.79       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[300 164]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[305 159]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[320 144]
 [176 598]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.69      0.67       464
           1       0.81      0.77      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[310 154]
 [166 608]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.67      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[310 154]
 [168 606]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.67      0.66       464
           1       0.80      0.78      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.73      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[306 158]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[319 145]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[308 156]
 [166 608]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[300 164]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[307 157]
 [165 609]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[315 149]
 [168 606]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.68      0.67       464
           1       0.80      0.78      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[309 155]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.67      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[293 171]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[305 159]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[302 162]
 [161 613]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.65      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[296 168]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[303 161]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.65      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[306 158]
 [159 615]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.80      0.79      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[313 151]
 [170 604]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.67      0.66       464
           1       0.80      0.78      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[296 168]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[296 168]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[285 179]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.61      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[292 172]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.63      0.65       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[306 158]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[298 166]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.67       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[298 166]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[292 172]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.63      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[308 156]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[300 164]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[301 163]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[310 154]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[310 154]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[307 157]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[293 171]
 [123 651]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.63      0.67       464
           1       0.79      0.84      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[304 160]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[306 158]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[310 154]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[304 160]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[306 158]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.66      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[313 151]
 [122 652]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.67      0.70       464
           1       0.81      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[316 148]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[312 152]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[316 148]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[305 159]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[308 156]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.66      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[314 150]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[308 156]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[320 144]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[310 154]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[313 151]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[316 148]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.70       464
           1       0.81      0.84      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[313 151]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[299 165]
 [125 649]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.64      0.67       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[309 155]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[317 147]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.70       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[311 153]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[309 155]
 [120 654]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.67      0.69       464
           1       0.81      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[319 145]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.68       464
           1       0.81      0.80      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[292 172]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.63      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[311 153]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.67       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[299 165]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[302 162]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[303 161]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.67       464
           1       0.80      0.81      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[321 143]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[319 145]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[300 164]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[321 143]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.70       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[322 142]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.83      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[305 159]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[301 163]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[307 157]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[309 155]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[310 154]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[309 155]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[315 149]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[319 145]
 [124 650]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[306 158]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.66      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[315 149]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[320 144]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[305 159]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[303 161]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[309 155]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[316 148]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[320 144]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[313 151]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[312 152]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[311 153]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[311 153]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[322 142]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.83      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[319 145]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[319 145]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[319 145]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[320 144]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[314 150]
 [159 615]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.68      0.67       464
           1       0.80      0.79      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.74      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[300 164]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[318 146]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.68       464
           1       0.81      0.80      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[309 155]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[313 151]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[304 160]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.75      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[298 166]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.64      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[311 153]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[300 164]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.66       464
           1       0.79      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[318 146]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[316 148]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[318 146]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[319 145]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.81      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[294 170]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.63      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[313 151]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[322 142]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.82      0.81      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[314 150]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[308 156]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[323 141]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.70      0.69       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[310 154]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[324 140]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.70      0.70       464
           1       0.82      0.82      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[310 154]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[324 140]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.70      0.71       464
           1       0.82      0.83      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.77      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[318 146]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[308 156]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[308 156]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[310 154]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[311 153]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[313 151]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[309 155]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[323 141]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.70      0.70       464
           1       0.82      0.83      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[323 141]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.70      0.71       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.77      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[319 145]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[317 147]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.70       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[319 145]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[319 145]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[302 162]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.65      0.66       464
           1       0.79      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[295 169]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[322 142]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.69       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.76      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[304 160]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[290 174]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[324 140]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.70      0.69       464
           1       0.82      0.81      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[329 135]
 [166 608]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.71      0.69       464
           1       0.82      0.79      0.80       774

    accuracy                           0.76      1238
   macro avg       0.74      0.75      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[304 160]
 [159 615]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[322 142]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[305 159]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[315 149]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[305 159]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[309 155]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[313 151]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[309 155]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[313 151]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[305 159]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[307 157]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[320 144]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[308 156]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[327 137]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.70      0.71       464
           1       0.82      0.82      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[311 153]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[308 156]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[298 166]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.84      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[314 150]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[311 153]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[318 146]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[305 159]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.66      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[300 164]
 [116 658]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.65      0.68       464
           1       0.80      0.85      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[313 151]
 [124 650]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.67      0.69       464
           1       0.81      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[315 149]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[302 162]
 [122 652]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.65      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[313 151]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[320 144]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[319 145]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 0.0001, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[317 147]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[298 166]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.64      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[296 168]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[292 172]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[293 171]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[289 175]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.62      0.63       464
           1       0.78      0.80      0.79       774

    accuracy                           0.73      1238
   macro avg       0.71      0.71      0.71      1238
weighted avg       0.73      0.73      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[289 175]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[ 12 452]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.03      0.05       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.82      0.51      0.41      1238
weighted avg       0.77      0.63      0.50      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[287 177]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[291 173]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[283 181]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.61      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[287 177]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[291 173]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[290 174]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[138 326]
 [ 71 703]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.30      0.41       464
           1       0.68      0.91      0.78       774

    accuracy                           0.68      1238
   macro avg       0.67      0.60      0.59      1238
weighted avg       0.67      0.68      0.64      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[ 67 397]
 [ 24 750]]

Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.14      0.24       464
           1       0.65      0.97      0.78       774

    accuracy                           0.66      1238
   macro avg       0.70      0.56      0.51      1238
weighted avg       0.68      0.66      0.58      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[149 315]
 [ 75 699]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.32      0.43       464
           1       0.69      0.90      0.78       774

    accuracy                           0.68      1238
   macro avg       0.68      0.61      0.61      1238
weighted avg       0.68      0.68      0.65      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[287 177]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[285 179]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.61      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[283 181]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.61      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[286 178]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[288 176]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[289 175]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[282 182]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.61      0.63       464
           1       0.77      0.81      0.79       774

    accuracy                           0.73      1238
   macro avg       0.71      0.71      0.71      1238
weighted avg       0.73      0.73      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[221 243]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.63      0.48      0.54       464
           1       0.73      0.83      0.78       774

    accuracy                           0.70      1238
   macro avg       0.68      0.65      0.66      1238
weighted avg       0.69      0.70      0.69      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[285 179]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.61      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.71      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[286 178]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[286 178]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[287 177]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[286 178]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[284 180]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.61      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[285 179]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.61      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[289 175]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[287 177]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[285 179]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.61      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[300 164]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[297 167]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[298 166]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[298 166]
 [166 608]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.64      0.64       464
           1       0.79      0.79      0.79       774

    accuracy                           0.73      1238
   macro avg       0.71      0.71      0.71      1238
weighted avg       0.73      0.73      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[295 169]
 [163 611]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.64      0.64       464
           1       0.78      0.79      0.79       774

    accuracy                           0.73      1238
   macro avg       0.71      0.71      0.71      1238
weighted avg       0.73      0.73      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[298 166]
 [163 611]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.64       464
           1       0.79      0.79      0.79       774

    accuracy                           0.73      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.73      0.73      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  1 463]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.81      0.50      0.39      1238
weighted avg       0.77      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[  3 461]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       1.00      0.01      0.01       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.81      0.50      0.39      1238
weighted avg       0.77      0.63      0.49      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[294 170]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[296 168]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[289 175]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.62      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.71      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[295 169]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[294 170]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[300 164]
 [163 611]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.65      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[100 364]
 [ 36 738]]

Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.22      0.33       464
           1       0.67      0.95      0.79       774

    accuracy                           0.68      1238
   macro avg       0.70      0.58      0.56      1238
weighted avg       0.69      0.68      0.62      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[203 261]
 [119 655]]

Classification Report:
              precision    recall  f1-score   support

           0       0.63      0.44      0.52       464
           1       0.72      0.85      0.78       774

    accuracy                           0.69      1238
   macro avg       0.67      0.64      0.65      1238
weighted avg       0.68      0.69      0.68      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[289 175]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[290 174]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.62      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[288 176]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[296 168]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[287 177]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.62      0.63       464
           1       0.78      0.80      0.79       774

    accuracy                           0.73      1238
   macro avg       0.72      0.71      0.71      1238
weighted avg       0.73      0.73      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[290 174]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.62      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[289 175]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[287 177]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[289 175]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[289 175]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[290 174]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[290 174]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[287 177]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[290 174]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[289 175]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[288 176]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[288 176]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[290 174]
 [146 628]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[304 160]
 [161 613]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[307 157]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[307 157]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[279 185]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.60      0.62       464
           1       0.77      0.79      0.78       774

    accuracy                           0.72      1238
   macro avg       0.70      0.70      0.70      1238
weighted avg       0.72      0.72      0.72      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[298 166]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[309 155]
 [173 601]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.67      0.65       464
           1       0.79      0.78      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[307 157]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.66      0.66       464
           1       0.80      0.80      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[301 163]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[302 162]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.66       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[303 161]
 [163 611]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.65      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[305 159]
 [161 613]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.66       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[299 165]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[264 200]
 [144 630]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.57      0.61       464
           1       0.76      0.81      0.79       774

    accuracy                           0.72      1238
   macro avg       0.70      0.69      0.70      1238
weighted avg       0.72      0.72      0.72      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 40


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 55


Neural Network - Learning_Rate = 0.001, Activation_Function = sigmoid, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[299 165]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[295 169]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.64       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[297 167]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[299 165]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[294 170]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[294 170]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[294 170]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.73      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[291 173]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[293 171]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[291 173]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[293 171]
 [154 620]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[292 172]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[294 170]
 [154 620]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[291 173]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.64       464
           1       0.78      0.81      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[288 176]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.73      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[294 170]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.63      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[290 174]
 [151 623]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[317 147]
 [173 601]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.68      0.66       464
           1       0.80      0.78      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[319 145]
 [183 591]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.69      0.66       464
           1       0.80      0.76      0.78       774

    accuracy                           0.74      1238
   macro avg       0.72      0.73      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[309 155]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.67      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[180 284]
 [103 671]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.39      0.48       464
           1       0.70      0.87      0.78       774

    accuracy                           0.69      1238
   macro avg       0.67      0.63      0.63      1238
weighted avg       0.68      0.69      0.67      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[312 152]
 [165 609]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.67      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[313 151]
 [163 611]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.67      0.67       464
           1       0.80      0.79      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[310 154]
 [164 610]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.67      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[282 182]
 [172 602]]

Classification Report:
              precision    recall  f1-score   support

           0       0.62      0.61      0.61       464
           1       0.77      0.78      0.77       774

    accuracy                           0.71      1238
   macro avg       0.69      0.69      0.69      1238
weighted avg       0.71      0.71      0.71      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[175 289]
 [ 96 678]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.38      0.48       464
           1       0.70      0.88      0.78       774

    accuracy                           0.69      1238
   macro avg       0.67      0.63      0.63      1238
weighted avg       0.68      0.69      0.67      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[307 157]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.66      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[298 166]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[301 163]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.65      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[258 206]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.63      0.56      0.59       464
           1       0.75      0.80      0.78       774

    accuracy                           0.71      1238
   macro avg       0.69      0.68      0.68      1238
weighted avg       0.70      0.71      0.71      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[284 180]
 [162 612]]

Classification Report:
              precision    recall  f1-score   support

           0       0.64      0.61      0.62       464
           1       0.77      0.79      0.78       774

    accuracy                           0.72      1238
   macro avg       0.70      0.70      0.70      1238
weighted avg       0.72      0.72      0.72      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[302 162]
 [159 615]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[300 164]
 [158 616]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.65      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[298 166]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[  0 464]
 [  0 774]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       464
           1       0.63      1.00      0.77       774

    accuracy                           0.63      1238
   macro avg       0.31      0.50      0.38      1238
weighted avg       0.39      0.63      0.48      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = sigmoid, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[296 168]
 [155 619]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[305 159]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.66      0.66       464
           1       0.80      0.80      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[289 175]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.62      0.65       464
           1       0.78      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.75      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[295 169]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.64      0.66       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[302 162]
 [160 614]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.65      0.65       464
           1       0.79      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[286 178]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.62      0.64       464
           1       0.78      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.71      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[297 167]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[344 120]
 [226 548]]

Classification Report:
              precision    recall  f1-score   support

           0       0.60      0.74      0.67       464
           1       0.82      0.71      0.76       774

    accuracy                           0.72      1238
   macro avg       0.71      0.72      0.71      1238
weighted avg       0.74      0.72      0.72      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[295 169]
 [157 617]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.64       464
           1       0.78      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[269 195]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.58      0.61       464
           1       0.76      0.81      0.79       774

    accuracy                           0.73      1238
   macro avg       0.71      0.70      0.70      1238
weighted avg       0.72      0.73      0.72      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[306 158]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[308 156]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[299 165]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[294 170]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.63      0.66       464
           1       0.79      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[307 157]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[306 158]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[296 168]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.64      0.66       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[307 157]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[287 177]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.62      0.64       464
           1       0.78      0.82      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[302 162]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.67       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[306 158]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[309 155]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[300 164]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[308 156]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[301 163]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.67       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[303 161]
 [125 649]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.65      0.68       464
           1       0.80      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[305 159]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[301 163]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[311 153]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[313 151]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[319 145]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[298 166]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[307 157]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[314 150]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[311 153]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[311 153]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 2, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[315 149]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[307 157]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[303 161]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.75      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[293 171]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.63      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[281 183]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.61      0.63       464
           1       0.77      0.81      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.71      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[301 163]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.65      0.66       464
           1       0.79      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[309 155]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[301 163]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.65      0.66       464
           1       0.79      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[257 207]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.55      0.60       464
           1       0.76      0.83      0.79       774

    accuracy                           0.72      1238
   macro avg       0.71      0.69      0.69      1238
weighted avg       0.72      0.72      0.72      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[294 170]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.63      0.66       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[296 168]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[310 154]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[309 155]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[293 171]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.63      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[299 165]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[315 149]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[308 156]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[306 158]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[312 152]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[305 159]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[307 157]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[310 154]
 [125 649]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[300 164]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[315 149]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[316 148]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[311 153]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[314 150]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[307 157]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[314 150]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[321 143]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.70       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[311 153]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[308 156]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[319 145]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[318 146]
 [121 653]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[318 146]
 [126 648]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[318 146]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 3, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[307 157]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[318 146]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.69      0.68       464
           1       0.81      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[306 158]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[319 145]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[295 169]
 [156 618]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.64      0.64       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[299 165]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.80       774

    accuracy                           0.74      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[307 157]
 [150 624]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.66      0.67       464
           1       0.80      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[280 184]
 [142 632]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.60      0.63       464
           1       0.77      0.82      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.71      1238
weighted avg       0.73      0.74      0.73      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[271 193]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.58      0.63       464
           1       0.77      0.83      0.80       774

    accuracy                           0.74      1238
   macro avg       0.72      0.71      0.71      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[299 165]
 [147 627]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.64      0.66       464
           1       0.79      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[313 151]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[303 161]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.65      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[308 156]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[299 165]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.64      0.66       464
           1       0.79      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[303 161]
 [148 626]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.65      0.66       464
           1       0.80      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[309 155]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[308 156]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[298 166]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.66       464
           1       0.79      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.76      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[312 152]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[308 156]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[300 164]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.65      0.67       464
           1       0.80      0.83      0.82       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[315 149]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.70       464
           1       0.81      0.84      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[312 152]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[314 150]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[319 145]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[326 138]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.70      0.71       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[315 149]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[313 151]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[311 153]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[317 147]
 [127 647]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.70       464
           1       0.81      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[324 140]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.70      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[311 153]
 [135 639]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[315 149]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[309 155]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[320 144]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[314 150]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.78      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 4, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[312 152]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[309 155]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.67      0.67       464
           1       0.80      0.80      0.80       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.74      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[311 153]
 [165 609]]

Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.67      0.66       464
           1       0.80      0.79      0.79       774

    accuracy                           0.74      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[313 151]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[306 158]
 [149 625]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.66      0.67       464
           1       0.80      0.81      0.80       774

    accuracy                           0.75      1238
   macro avg       0.74      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[314 150]
 [152 622]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.68      0.68       464
           1       0.81      0.80      0.80       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[295 169]
 [154 620]]

Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.64      0.65       464
           1       0.79      0.80      0.79       774

    accuracy                           0.74      1238
   macro avg       0.72      0.72      0.72      1238
weighted avg       0.74      0.74      0.74      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[292 172]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.63      0.65       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[308 156]
 [153 621]]

Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.66      0.67       464
           1       0.80      0.80      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.73      0.73      1238
weighted avg       0.75      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 16, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[299 165]
 [134 640]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.64      0.67       464
           1       0.80      0.83      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[302 162]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.65      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.75      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[310 154]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[314 150]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[291 173]
 [139 635]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.63      0.65       464
           1       0.79      0.82      0.80       774

    accuracy                           0.75      1238
   macro avg       0.73      0.72      0.73      1238
weighted avg       0.74      0.75      0.75      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[319 145]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[305 159]
 [140 634]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.66      0.67       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[312 152]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[311 153]
 [145 629]]

Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.67      0.68       464
           1       0.80      0.81      0.81       774

    accuracy                           0.76      1238
   macro avg       0.74      0.74      0.74      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 32, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[310 154]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[319 145]
 [143 631]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.69      0.69       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[319 145]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.69       464
           1       0.81      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[311 153]
 [137 637]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[309 155]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.67      0.68       464
           1       0.80      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[308 156]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[314 150]
 [141 633]]

Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.68      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.76      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.76      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[313 151]
 [130 644]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[308 156]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.66      0.68       464
           1       0.80      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 64, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[311 153]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.75      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 25

Confusion Matrix:
[[310 154]
 [136 638]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.67      0.68       464
           1       0.81      0.82      0.81       774

    accuracy                           0.77      1238
   macro avg       0.75      0.75      0.75      1238
weighted avg       0.76      0.77      0.76      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 40

Confusion Matrix:
[[309 155]
 [124 650]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69       464
           1       0.81      0.84      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 512, Patience = 55

Confusion Matrix:
[[321 143]
 [138 636]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.69      0.70       464
           1       0.82      0.82      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.77      0.77      0.77      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 25

Confusion Matrix:
[[326 138]
 [132 642]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.70      0.71       464
           1       0.82      0.83      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.77      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 40

Confusion Matrix:
[[322 142]
 [129 645]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 1024, Patience = 55

Confusion Matrix:
[[322 142]
 [131 643]]

Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.69      0.70       464
           1       0.82      0.83      0.82       774

    accuracy                           0.78      1238
   macro avg       0.76      0.76      0.76      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 25

Confusion Matrix:
[[318 146]
 [124 650]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.84      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 40

Confusion Matrix:
[[322 142]
 [128 646]]

Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.69      0.70       464
           1       0.82      0.83      0.83       774

    accuracy                           0.78      1238
   macro avg       0.77      0.76      0.77      1238
weighted avg       0.78      0.78      0.78      1238


Neural Network - Learning_Rate = 1e-05, Activation_Function = relu, Hidden_Layers = 5, Neurons = 128, Batch_Size = 3318, Patience = 55

Confusion Matrix:
[[315 149]
 [133 641]]

Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.68      0.69       464
           1       0.81      0.83      0.82       774

    accuracy                           0.77      1238
   macro avg       0.76      0.75      0.76      1238
weighted avg       0.77      0.77      0.77      1238
